{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    " words = \"谁呼吁,谁呼吁，非洲国家需要密切合作，分享情报，以防范和对抗这些武装分子\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['谁', '呼吁', '谁', '呼吁', '非洲', '国家', '需要', '密切合作', '分享', '情报', '以', '防范', '和', '对抗', '这些', '武装', '分子']\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import regex\n",
    "pattern = regex.compile(r'[\\p{P}]',flags=regex.MULTILINE)\n",
    "words = regex.sub(pattern,' ',words)\n",
    "#print(words)\n",
    "words = ' '.join(jieba.cut(words)).split()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_fn=filter_ngram\n",
    "# def filter_ngram(gram, mode='any'):\n",
    "#     \"\"\"Decide whether to keep or discard an n-gram.\n",
    "\n",
    "#     Args:\n",
    "#         gram: list of tokens (length N)\n",
    "#         mode: Option to throw out ngram if\n",
    "#           'any': any single token passes filter_word\n",
    "#           'all': all tokens pass filter_word\n",
    "#           'ends': book-ended by filterable tokens\n",
    "#     \"\"\"\n",
    "#     filtered = [w for w in gram]\n",
    "#     if mode == 'any':\n",
    "#         return any(filtered)\n",
    "#     elif mode == 'all':\n",
    "#         return all(filtered)\n",
    "#     elif mode == 'ends':\n",
    "#         return filtered[0] or filtered[-1]\n",
    "#     else:\n",
    "#         raise ValueError('Invalid mode: %s' % mode)\n",
    "\n",
    "# def _skip(gram):\n",
    "#     if not filter_fn:\n",
    "#         return False\n",
    "#     return filter_fn(gram)\n",
    "ngrams = [(s, e + 1)\n",
    "          for s in range(len(words))\n",
    "          for e in range(s, min(s+2, len(words)))\n",
    "          ]\n",
    "ngrams = ['{}'.format(''.join(words[s:e])) for (s, e) in ngrams]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11051710, 13588682, 4653419, 13132509, 11051710, 13588682, 4653419, 1397643, 11050379, 16513735, 3933601, 12787765, 12920882, 16367825, 1995225, 14593104, 4004785, 9601776, 7484471, 3142021, 13357947, 14874875, 1496136, 6641060, 15193131, 16735529, 10564454, 2975580, 1307783, 561928, 8562613, 14308521, 3412780]\n",
      "[  561928  1307783  1397643  1496136  1995225  2975580  3142021  3412780\n",
      "  3933601  4004785  4653419  6641060  7484471  8562613  9601776 10564454\n",
      " 11050379 11051710 12787765 12920882 13132509 13357947 13588682 14308521\n",
      " 14593104 14874875 15193131 16367825 16513735 16735529] [1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# print(ngrams)\n",
    "hash_size = int(math.pow(2, 24))\n",
    "def hash(token, num_buckets):\n",
    "    \"\"\"Unsigned 32 bit murmurhash for feature hashing.\"\"\"\n",
    "    return murmurhash3_32(token, positive=True) % num_buckets\n",
    "hash_query = [hash(gram, hash_size) for gram in ngrams]\n",
    "print(hash_query)\n",
    "q_unique, q_counts = np.unique(hash_query, return_counts=True)\n",
    "print(q_unique, q_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import murmurhash3_32\n",
    "hash_size = int(math.pow(2, 24))\n",
    "def hash(token, num_buckets):\n",
    "    \"\"\"Unsigned 32 bit murmurhash for feature hashing.\"\"\"\n",
    "    return murmurhash3_32(token, positive=True) % num_buckets\n",
    "from collections import Counter\n",
    "counts = Counter([hash(gram, hash_size) for gram in ngrams])\n",
    "print(counts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  770155  1384740  1558814  2042392  2505460  2769724  2983307  4379415\n",
      "  4904872  6233483  7339260  7563661  9860422 10197377 11089724 11247795\n",
      " 11413059 11817359 11932104 12175726 12426006 13258946 15070961 15481880\n",
      " 15754994 15770481]\n",
      "[1 1 1 1 1 1 1 2 1 1 1 1 1 2 2 1 1 2 2 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import murmurhash3_32\n",
    "from collections import Counter\n",
    "import math\n",
    "row, col, data = [], [], []\n",
    "hash_size = int(math.pow(2, 24))\n",
    "def hash(token, num_buckets):\n",
    "    \"\"\"Unsigned 32 bit murmurhash for feature hashing.\"\"\"\n",
    "    return murmurhash3_32(token, positive=True) % num_buckets\n",
    "hash_ans = [hash(gram, hash_size) for gram in ngrams]\n",
    "wids_unique, wids_counts = np.unique(hash_ans, return_counts=True)\n",
    "print(wids_unique)\n",
    "print(wids_counts)\n",
    "#counts = Counter(hash_ans)\n",
    "\n",
    "# row.extend(counts.keys())\n",
    "# col.extend([0]*len(counts))\n",
    "# data.extend(counts.values())\n",
    "# print('shape....', len(row), len(col), len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array([0,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "count_matrix = csr_matrix(\n",
    "        (data, (row, col)), shape=(hash_size, 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix.sum_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = -1\n",
    "idfs[idfs < 0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x1 = np.arange(9.0).reshape((3, 3))\n",
    "x2 = np.arange(3.0)\n",
    "np.multiply(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1]\n",
      " [0 0 2]\n",
      " [0 3 4]]\n",
      "[2 1 2]\n",
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "row = np.array([0, 0, 1, 2, 2, 2])\n",
    "col = np.array([0, 2, 2, 0, 1, 2])\n",
    "data = np.array([1, 1, 2, 0, 3, 4])\n",
    "matrix = csr_matrix((data, (row, col)), shape=(3, 3))\n",
    "print(matrix.toarray())\n",
    "tf = matrix.log1p()\n",
    "\n",
    "binary = (matrix>0).astype(int)\n",
    "freqs = np.array(binary.sum(1)).squeeze()\n",
    "print(freqs)\n",
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.toarray()>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = np.log((matrix.shape[1] - Ns + 0.5) / (Ns + 0.5))\n",
    "idfs[idfs < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1,-1,2,3])\n",
    "arr[arr<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count()-1 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "print(math.pow(2,23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.random.randomint(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randint(15,size=20)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argpartition(-data,15)[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = idx[np.argsort(-data[idx])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"并寻求快速的商业回报。特别是中国等竞争对手已把人工智能列为国家发展重点，且在如何发展上远比西方国家更加激进？特别是中国等竞争对手已把人工智能列为国家发展重点，且在如何发展上远比西方国家更加激进！特别是中国等竞争对手已把人工智能列为国家发展重点，且在如何发展上远比西方国家更加激进?特别是中国等竞争对手已把人工智能列为国家发展重点，且在如何发展上远比西方国家更加激进!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "content_list = re.split('[！？。!?]',content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"2018年1月底，英国《经济学人》网站刊发一系列以未来战争为主题的文章，从多个维度阐述对未来战争特点和形态的看法。\t发展远程传感器、精确打击网络以及网络和空间能力是俄罗斯与中国的灰色地带战略取得成功的一个关键原因，这些能力将对美国区域力量投送造成无法接受的成本。潜在对手国家一直在研究西方作战的薄弱环节，并开发更廉价、更易获得的技术，技术研发从军事机构流入民用和商业部门也使这些国家受益。\t高端竞争环境\t尽管美国的军事力量在战略层面依然领先，但主要对手对反介入/区域拒止（A2/AD）能力投资已经大大缩小了与美国的技术优势，美国已无法在冲突发生的初期阶段继续依靠地区霸权来解决问题。俄罗斯不断增长的A2/AD能力对美国及其盟友也构成了同样的挑战，位于俄罗斯加里宁格勒和西部的导弹系统可能会使波罗的海变成北约海军舰艇的禁区。伊朗的情况也类似，有能力威胁到包括美国航母和空军基地在内的海湾地区航运。\t中国的渐进式战术\t中国的各种努力主要是为了降级美军的海上和陆上航空力量，进而限制美国可能发动的战争类型。第一步是实现信息优势，即使用激光致盲卫星或网络攻击破坏计算机系统等手段瞄准美国的数据和通信网络，尤其是太空中的网络。为防范美国靠近中国海域作战，中国可利用数量众多的陆基防空和反舰导弹以及快速导弹艇、导弹潜艇和海上攻击机等打击美国海军舰艇以及在关岛与日本的军事基地，特别是中国企图迫使美国航母远离中国海域，或向其施加被反舰弹道导弹毁灭的风险。中国研制了被称为航母杀手的DF-21D中程弹道导弹；也在建设一支强大的、拥有国产航母的蓝水海军，还在南中国海为其增设全副武装的人造岛屿。美国的第三次抵消战略\t美国防部宣布实施第三次抵消战略，希望遏制并挫败中国的步步威胁，推进实现美国利益，保护亚太地区地区以及世界所有地区的盟友。第三次抵消战略旨在利用新兴技术来重建美国对高端对手的压倒性竞争优势，进而实现向强对抗环境投送兵力的能力。但与前两次实现长期技术优势的战略不同，这一次美国的领先地位可能会更短暂。其中一个原因是人工智能、深度机器学习、机器人和自主性等众多关键使能技术的创新速度已经加快；另一个原因是民用部门正在推动这些技术的研发投资，并寻求快速的商业回报。俄罗斯、特别是中国等竞争对手已把人工智能列为国家发展重点，且在如何发展上远比西方国家更加激进。\t尽管如此，美国重建技术优势的努力仍会有所回报，美国的国防支出是中国的三倍，美军拥有比其他对手更多的作战经验，且在系统工程方面享有其他国家无法比拟的优势，在商业人工智能的投资方面也处于领跑趋势。\t高性价比的技术对策\t美战略和预算评估中心研究员表示，美国应该将新技术应用于水下、打击、空中和电磁等四个主要作战域。\t①水下作战。可部署难以探测的小型无人潜航器执行扫雷、在浅水区搜寻敌方潜艇以及收集情报等任务，而大型无人机潜航器可以用来搭载海底长效传感器、其它无人潜航器的动力包以及有人驾驶潜艇的导弹等有效载荷。\t②空中作战。可通过干扰敌方传感器和控制系统来降级对手的一体化防空系统（IAD），然后派出组网的小型无人机蜂群给与进一步的打击，最后部署B-2和新开发的B-21等突防型远程隐身轰炸机。为实现地区霸权，美军需要探测距离更远的传感器和激光器来侦察敌机。\t③电子战。电磁频谱优势将变得愈加重要。获取这种优势的新手段包括掩盖船舶和飞机雷达特征的隐身技术、保护天基通信网络免受攻击、发射诱饵并防御来袭的导弹齐射威胁等。\t目前，美国防部落后的采办系统很难适应新形势发展，为了尽快跟上创新的步伐，前国防部副部长沃克表示国防部必须模仿硅谷模式，转向快速原型并改变对试验的态度，寻求与商业公司合作开发关键技术。美国防部还成立了                                  国防创新实验单元，与之前从未合作过的公司建立合作。来源：英国《经济学人》\t2018-02-26国防科技要闻\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = content.replace(' ', '').replace(' ', '').replace('　', '')\n",
    "content = content.replace(\"``\", '\" ').replace('\\n', '')\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "print(math.pow(2,23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5.45813042/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' djsklajkld '.strip().find('l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "130996/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Q: 无人机群集成被简称为？'.find('Q:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 17,   4,  78,  13,   8, 106, 106,  22,  19,  64,  62,  36, 101,\n",
       "        84,  15, 114,  10,  73,  63, 109,  35,  26,  93,  15,  80,  89,\n",
       "         8,  95,  33,  69, 103,  19,  59,  35,  33,  22,  15,  55, 100,\n",
       "        99])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "np.random.randint(120,size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"？他们将对非洲大陆的安全构成严重隐患，”非盟和平与安全事务专员斯梅尔。谢尔吉呼吁，非洲国家需要密切合作，分享情报，以防范和对抗这些武装分子。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'他们将对非洲大陆的安全构成严重隐患，”非盟和平与安全事务专员斯梅尔。谢尔吉呼吁，非洲国家需要密切合作，分享情报，以防范和对抗这些武装分子'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.strip(\"[！？。!?]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
